{
 "cells": [
  {
   "cell_type": "raw",
   "id": "199b8709",
   "metadata": {},
   "source": [
    "-Ứng dụng mô hình Markov vào học máy để huấn luyện dữ liệu dataset: NSL-KDD.\n",
    "-Tham khảo phương pháp đánh giá: Confusion Matrix, …\n",
    "-Nghiên cứu phương pháp chiết suất đặc trưng kỹ thuật phân cụm: DBSCAN, K-means, …\n",
    "So sánh, đánh giá hiệu quả các mô hình: Markov, CNN;\n",
    "sau khi thực hiện Epoch = 50 cho mỗi mô hình, cho mỗi loại tấn công"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ace0e4",
   "metadata": {},
   "source": [
    "\n",
    "# 1. IMPORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "17a93df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import scipy.cluster.hierarchy as shc\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split \n",
    "import matplotlib.patheffects as PathEffects\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "# importing required libraries for normalizing data\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.preprocessing import LabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "59d77f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.layers import Dense, LSTM, MaxPool1D, Flatten, Dropout,Conv1D # importing dense layer\n",
    "from keras.models import Sequential #importing Sequential layer\n",
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "# representation of model layers\n",
    "from keras.utils.vis_utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5ab70217",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature=[\"duration\",\"protocol_type\",\"service\",\"flag\",\"src_bytes\",\"dst_bytes\",\"land\",\"wrong_fragment\",\"urgent\",\"hot\",\n",
    "          \"num_failed_logins\",\"logged_in\",\"num_compromised\",\"root_shell\",\"su_attempted\",\"num_root\",\"num_file_creations\",\"num_shells\",\n",
    "          \"num_access_files\",\"num_outbound_cmds\",\"is_host_login\",\"is_guest_login\",\"count\",\"srv_count\",\"serror_rate\",\"srv_serror_rate\",\n",
    "          \"rerror_rate\",\"srv_rerror_rate\",\"same_srv_rate\",\"diff_srv_rate\",\"srv_diff_host_rate\",\"dst_host_count\",\"dst_host_srv_count\", \n",
    "          \"dst_host_same_srv_rate\",\"dst_host_diff_srv_rate\",\"dst_host_same_src_port_rate\",\"dst_host_srv_diff_host_rate\",\"dst_host_serror_rate\",\n",
    "          \"dst_host_srv_serror_rate\",\"dst_host_rerror_rate\",\"dst_host_srv_rerror_rate\",\"label\",\"difficulty\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4e22a7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train='./KDDTrain+.txt'\n",
    "test='./KDDTest+.txt'\n",
    "data=pd.read_csv(train,names=feature)\n",
    "test_data=pd.read_csv(test,names=feature)\n",
    "df= pd.concat([data, test_data], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ba109f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# phân loại lớp \n",
    "def change_label(df):\n",
    "  df.label.replace(['apache2','back','land','neptune','mailbomb','pod','processtable','smurf','teardrop','udpstorm','worm'],'Dos',inplace=True)\n",
    "  df.label.replace(['ftp_write','guess_passwd','httptunnel','imap','multihop','named','phf','sendmail','snmpgetattack','snmpguess','spy','warezclient','warezmaster','xlock','xsnoop'],'R2L',inplace=True)      \n",
    "  df.label.replace(['ipsweep','mscan','nmap','portsweep','saint','satan'],'Probe',inplace=True)\n",
    "  df.label.replace(['buffer_overflow','loadmodule','perl','ps','rootkit','sqlattack','xterm'],'U2R',inplace=True)\n",
    "\n",
    "change_label(df)\n",
    "# change_label(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c596680e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# xóa 'difficulty_level'\n",
    "df.drop(['difficulty'],axis=1,inplace=True)\n",
    "#test_data.drop(['difficulty'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fed08a2",
   "metadata": {},
   "source": [
    "\n",
    "# 2. BIẾN ĐỔI VÀ CHUẨN HÓA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ef892a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot-encoding categorical columns\n",
    "df = pd.get_dummies(df,columns=['protocol_type','service','flag'],prefix=\"\",prefix_sep=\"\")  \n",
    "#print(data.shape)\n",
    "#test_data = pd.get_dummies(test_data,columns=['protocol_type','service','flag'],prefix=\"\",prefix_sep=\"\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5ced8ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tạo datafreame labels (Dos,Probe,R2L,U2R,normal)\n",
    "label = pd.DataFrame(df.label)\n",
    "#label_test = pd.DataFrame(test_data.label)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2cf5f478",
   "metadata": {},
   "source": [
    "# le2 = preprocessing.LabelEncoder()\n",
    "enc_label = label_test.apply(le2.fit_transform)\n",
    "test_data['intrusion'] = enc_label\n",
    "print(test_data.shape)\n",
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2732719a",
   "metadata": {},
   "outputs": [],
   "source": [
    "minmax_scaler = MinMaxScaler()\n",
    "def normalization(df, col):\n",
    "    for i in col:\n",
    "        arr = df[i]\n",
    "        arr = np.array(arr)\n",
    "        df[i] = minmax_scaler.fit_transform(arr.reshape(len(arr), 1))\n",
    "    return df\n",
    "#chuẩn hóa dữ liệu số của data\n",
    "numeric_col = df.select_dtypes(include='number').columns\n",
    "df = normalization(df, numeric_col)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "49720a92",
   "metadata": {},
   "source": [
    "std_scaler = StandardScaler()\n",
    "def standardization(df,col):\n",
    "    for i in col:\n",
    "        arr = df[i]\n",
    "        arr = np.array(arr)\n",
    "        df[i] = std_scaler.fit_transform(arr.reshape(len(arr),1))\n",
    "    return df\n",
    "\n",
    "#chuẩn hóa dữ liệu số của data\n",
    "numeric_col = df.select_dtypes(include='number').columns\n",
    "df = standardization(df, numeric_col)\n",
    "#chuẩn hóa dữ liệu số của test_data\n",
    "#numeric_col = test_data.select_dtypes(include='number').columns\n",
    "#test_data = normalization(test_data, numeric_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f5ea21e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(148517, 124)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\satra\\AppData\\Local\\Temp\\ipykernel_11144\\2616363727.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['intrusion'] = enc_label\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>src_bytes</th>\n",
       "      <th>dst_bytes</th>\n",
       "      <th>land</th>\n",
       "      <th>wrong_fragment</th>\n",
       "      <th>urgent</th>\n",
       "      <th>hot</th>\n",
       "      <th>num_failed_logins</th>\n",
       "      <th>logged_in</th>\n",
       "      <th>num_compromised</th>\n",
       "      <th>...</th>\n",
       "      <th>RSTO</th>\n",
       "      <th>RSTOS0</th>\n",
       "      <th>RSTR</th>\n",
       "      <th>S0</th>\n",
       "      <th>S1</th>\n",
       "      <th>S2</th>\n",
       "      <th>S3</th>\n",
       "      <th>SF</th>\n",
       "      <th>SH</th>\n",
       "      <th>intrusion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.558064e-07</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.057999e-07</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.681203e-07</td>\n",
       "      <td>6.223962e-06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.442067e-07</td>\n",
       "      <td>3.206260e-07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148512</th>\n",
       "      <td>0.0</td>\n",
       "      <td>5.753774e-07</td>\n",
       "      <td>2.542106e-07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148513</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.297162e-07</td>\n",
       "      <td>7.160648e-07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148514</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.952277e-05</td>\n",
       "      <td>6.346868e-06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.019802</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000134</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148515</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.043558e-08</td>\n",
       "      <td>3.206260e-08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148516</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>148517 rows × 124 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        duration     src_bytes     dst_bytes  land  wrong_fragment  urgent  \\\n",
       "0            0.0  3.558064e-07  0.000000e+00   0.0             0.0     0.0   \n",
       "1            0.0  1.057999e-07  0.000000e+00   0.0             0.0     0.0   \n",
       "2            0.0  0.000000e+00  0.000000e+00   0.0             0.0     0.0   \n",
       "3            0.0  1.681203e-07  6.223962e-06   0.0             0.0     0.0   \n",
       "4            0.0  1.442067e-07  3.206260e-07   0.0             0.0     0.0   \n",
       "...          ...           ...           ...   ...             ...     ...   \n",
       "148512       0.0  5.753774e-07  2.542106e-07   0.0             0.0     0.0   \n",
       "148513       0.0  2.297162e-07  7.160648e-07   0.0             0.0     0.0   \n",
       "148514       0.0  3.952277e-05  6.346868e-06   0.0             0.0     0.0   \n",
       "148515       0.0  3.043558e-08  3.206260e-08   0.0             0.0     0.0   \n",
       "148516       0.0  0.000000e+00  0.000000e+00   0.0             0.0     0.0   \n",
       "\n",
       "             hot  num_failed_logins  logged_in  num_compromised  ...  RSTO  \\\n",
       "0       0.000000                0.0        0.0         0.000000  ...   0.0   \n",
       "1       0.000000                0.0        0.0         0.000000  ...   0.0   \n",
       "2       0.000000                0.0        0.0         0.000000  ...   0.0   \n",
       "3       0.000000                0.0        1.0         0.000000  ...   0.0   \n",
       "4       0.000000                0.0        1.0         0.000000  ...   0.0   \n",
       "...          ...                ...        ...              ...  ...   ...   \n",
       "148512  0.000000                0.0        1.0         0.000000  ...   0.0   \n",
       "148513  0.000000                0.0        1.0         0.000000  ...   0.0   \n",
       "148514  0.019802                0.0        1.0         0.000134  ...   0.0   \n",
       "148515  0.000000                0.0        0.0         0.000000  ...   0.0   \n",
       "148516  0.000000                0.0        0.0         0.000000  ...   0.0   \n",
       "\n",
       "        RSTOS0  RSTR   S0   S1   S2   S3   SF   SH  intrusion  \n",
       "0          0.0   0.0  0.0  0.0  0.0  0.0  1.0  0.0          4  \n",
       "1          0.0   0.0  0.0  0.0  0.0  0.0  1.0  0.0          4  \n",
       "2          0.0   0.0  1.0  0.0  0.0  0.0  0.0  0.0          0  \n",
       "3          0.0   0.0  0.0  0.0  0.0  0.0  1.0  0.0          4  \n",
       "4          0.0   0.0  0.0  0.0  0.0  0.0  1.0  0.0          4  \n",
       "...        ...   ...  ...  ...  ...  ...  ...  ...        ...  \n",
       "148512     0.0   0.0  0.0  0.0  0.0  0.0  1.0  0.0          4  \n",
       "148513     0.0   0.0  0.0  0.0  0.0  0.0  1.0  0.0          4  \n",
       "148514     0.0   0.0  0.0  0.0  0.0  0.0  1.0  0.0          0  \n",
       "148515     0.0   0.0  0.0  0.0  0.0  0.0  1.0  0.0          4  \n",
       "148516     0.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0          1  \n",
       "\n",
       "[148517 rows x 124 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le2 = preprocessing.LabelEncoder()\n",
    "enc_label = label.apply(le2.fit_transform)\n",
    "df['intrusion'] = enc_label\n",
    "print(df.shape)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "32aa7c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phân 4 loại tấn công của bộ train vào dataframe\n",
    "# Tạo 4 dataframe mới\n",
    "DoS_df = pd.DataFrame()\n",
    "Probe_df = pd.DataFrame()\n",
    "R2L_df = pd.DataFrame()\n",
    "U2R_df = pd.DataFrame()\n",
    "normal_df = pd.DataFrame()\n",
    "\n",
    "# Nhóm các mẫu theo nhãn và lưu vào các dataframe tương ứng\n",
    "for label, group in df.groupby('label'):\n",
    "    if label == 'Dos':\n",
    "        DoS_df = pd.concat([DoS_df, group], axis=0)\n",
    "    elif label == 'Probe' :\n",
    "        Probe_df = pd.concat([Probe_df, group], axis=0)\n",
    "    elif label == 'R2L' :\n",
    "        R2L_df = pd.concat([R2L_df, group], axis=0)\n",
    "    elif label == 'U2R' :\n",
    "        U2R_df = pd.concat([U2R_df, group], axis=0)\n",
    "    elif label == 'normal':\n",
    "        normal_df = pd.concat([normal_df, group], axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ae3e5928",
   "metadata": {},
   "outputs": [],
   "source": [
    "DoS_df.drop(labels= ['label'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c80335dd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "YDoS_train = DoS_df['intrusion']\n",
    "XDoS_train = DoS_df.drop(labels= ['intrusion'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "606217d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "YDoS_train = LabelBinarizer().fit_transform(YDoS_train)\n",
    "\n",
    "XDoS_train=np.array(XDoS_train)\n",
    "YDoS_train=np.array(YDoS_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "aeede850",
   "metadata": {},
   "outputs": [],
   "source": [
    "XDoS_train, XDoS_test, YDoS_train, YDoS_test = train_test_split(XDoS_train, YDoS_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c7e5613a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape input to be [samples, time steps, features]\n",
    "XDoS_train = np.reshape(XDoS_train, ( XDoS_train.shape[0], XDoS_train.shape[1],1 ))\n",
    "XDoS_test = np.reshape(XDoS_test, ( XDoS_test.shape[0],  XDoS_test.shape[1],1 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "617fc4c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(104352, 122, 1)\n",
      "(26089, 122, 1)\n",
      "(104352, 1)\n",
      "(26089, 1)\n"
     ]
    }
   ],
   "source": [
    "print(XDoS_train.shape)\n",
    "print(XDoS_test.shape)\n",
    "print(YDoS_train.shape)\n",
    "print(YDoS_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "48836fe6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(104352, 122, 1)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XDoS_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "587d97b7",
   "metadata": {},
   "source": [
    "# K-MEANS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522d2454",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters = 8\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "kmeans.fit(X_train)\n",
    "\n",
    "# Chiết xuất đặc trưng của các cụm tấn công\n",
    "cluster_features = []\n",
    "for i in range(n_clusters):\n",
    "    indices = np.where(kmeans.labels_ == i)[0]\n",
    "    cluster_data = X_train[indices]\n",
    "    cluster_feature = np.mean(cluster_data, axis=0)\n",
    "    cluster_features.append(cluster_feature)\n",
    "\n",
    "# Sử dụng đặc trưng để huấn luyện mô hình\n",
    "clf = RandomForestClassifier(random_state=42)\n",
    "clf.fit(cluster_features, range(n_clusters))\n",
    "\n",
    "# Dự đoán cụm của các dữ liệu test\n",
    "test_cluster_labels = kmeans.predict(X_test)\n",
    "\n",
    "# Dự đoán nhãn tấn công của các dữ liệu test\n",
    "test_pred = np.zeros_like(y_test)\n",
    "for i in range(len(test_pred)):\n",
    "    cluster_feature = cluster_features[test_cluster_labels[i]]\n",
    "    test_pred[i] = clf.predict([cluster_feature])\n",
    "    \n",
    "# Đánh giá kết quả bằng confusion matrix\n",
    "confusion = confusion_matrix(y_test, test_pred)\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db7a331",
   "metadata": {},
   "source": [
    "# MÔ HÌNH MARKOV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99815243",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1dfb96d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "104ca0af",
   "metadata": {},
   "source": [
    "# MÔ HÌNH CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a7c48e",
   "metadata": {},
   "source": [
    "#  - DoS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "44669db1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_6 (Conv1D)           (None, 120, 32)           128       \n",
      "                                                                 \n",
      " max_pooling1d_5 (MaxPooling  (None, 40, 32)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " flatten_5 (Flatten)         (None, 1280)              0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 128)               163968    \n",
      "                                                                 \n",
      " dropout_13 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 164,225\n",
      "Trainable params: 164,225\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# create CNN model\n",
    "model1 = Sequential()\n",
    "\n",
    "# add convolutional layer with 32 filters, kernel size of 3x3 and activation function ReLU\n",
    "model1.add(Conv1D(32, kernel_size=3,activation='relu', input_shape=( XDoS_train.shape[1],XDoS_train.shape[2])))\n",
    "\n",
    "# add max pooling layer\n",
    "model1.add(MaxPool1D(pool_size=3))\n",
    "\n",
    "# add flatten layer to convert output of convolutional layer to 1D array\n",
    "model1.add(Flatten())\n",
    "\n",
    "\n",
    "# add dense layer with 128 neurons and activation function ReLU\n",
    "model1.add(Dense(128, activation='relu'))\n",
    "\n",
    "# add dropout layer with rate of 0.2 to prevent overfitting\n",
    "model1.add(Dropout(0.2))\n",
    "\n",
    "# add output layer with 1 neuron and sigmoid activation function for binary classification\n",
    "model1.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# compile model with binary crossentropy loss function and Adam optimizer\n",
    "model1.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# print model summary\n",
    "model1.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "141b03b6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "3261/3261 [==============================] - 19s 5ms/step - loss: 0.0554 - accuracy: 0.9841 - val_loss: 0.0321 - val_accuracy: 0.9910\n",
      "Epoch 2/50\n",
      "3261/3261 [==============================] - 18s 6ms/step - loss: 0.0270 - accuracy: 0.9911 - val_loss: 0.0201 - val_accuracy: 0.9934\n",
      "Epoch 3/50\n",
      "3261/3261 [==============================] - 17s 5ms/step - loss: 0.0161 - accuracy: 0.9945 - val_loss: 0.0109 - val_accuracy: 0.9972\n",
      "Epoch 4/50\n",
      "3261/3261 [==============================] - 19s 6ms/step - loss: 0.0122 - accuracy: 0.9958 - val_loss: 0.0107 - val_accuracy: 0.9971\n",
      "Epoch 5/50\n",
      "3261/3261 [==============================] - 17s 5ms/step - loss: 0.0115 - accuracy: 0.9962 - val_loss: 0.0120 - val_accuracy: 0.9965\n",
      "Epoch 6/50\n",
      "3261/3261 [==============================] - 18s 6ms/step - loss: 0.0099 - accuracy: 0.9967 - val_loss: 0.0126 - val_accuracy: 0.9969\n",
      "Epoch 7/50\n",
      "3261/3261 [==============================] - 19s 6ms/step - loss: 0.0089 - accuracy: 0.9970 - val_loss: 0.0106 - val_accuracy: 0.9977\n",
      "Epoch 8/50\n",
      "3261/3261 [==============================] - 18s 6ms/step - loss: 0.0085 - accuracy: 0.9973 - val_loss: 0.0148 - val_accuracy: 0.9961\n",
      "Epoch 9/50\n",
      "3261/3261 [==============================] - 18s 6ms/step - loss: 0.0083 - accuracy: 0.9973 - val_loss: 0.0104 - val_accuracy: 0.9977\n",
      "Epoch 10/50\n",
      "3261/3261 [==============================] - 20s 6ms/step - loss: 0.0083 - accuracy: 0.9973 - val_loss: 0.0106 - val_accuracy: 0.9978\n",
      "Epoch 11/50\n",
      "3261/3261 [==============================] - 19s 6ms/step - loss: 0.0073 - accuracy: 0.9976 - val_loss: 0.0133 - val_accuracy: 0.9973\n",
      "Epoch 12/50\n",
      "3261/3261 [==============================] - 18s 6ms/step - loss: 0.0072 - accuracy: 0.9975 - val_loss: 0.0120 - val_accuracy: 0.9965\n",
      "Epoch 13/50\n",
      "3261/3261 [==============================] - 20s 6ms/step - loss: 0.0068 - accuracy: 0.9977 - val_loss: 0.0100 - val_accuracy: 0.9976\n",
      "Epoch 14/50\n",
      "3261/3261 [==============================] - 19s 6ms/step - loss: 0.0067 - accuracy: 0.9978 - val_loss: 0.0104 - val_accuracy: 0.9977\n",
      "Epoch 15/50\n",
      "3261/3261 [==============================] - 19s 6ms/step - loss: 0.0066 - accuracy: 0.9977 - val_loss: 0.0095 - val_accuracy: 0.9976\n",
      "Epoch 16/50\n",
      "3261/3261 [==============================] - 18s 6ms/step - loss: 0.0066 - accuracy: 0.9977 - val_loss: 0.0109 - val_accuracy: 0.9977\n",
      "Epoch 17/50\n",
      "3261/3261 [==============================] - 18s 6ms/step - loss: 0.0060 - accuracy: 0.9978 - val_loss: 0.0107 - val_accuracy: 0.9974\n",
      "Epoch 18/50\n",
      "3261/3261 [==============================] - 19s 6ms/step - loss: 0.0058 - accuracy: 0.9980 - val_loss: 0.0103 - val_accuracy: 0.9978\n",
      "Epoch 19/50\n",
      "3261/3261 [==============================] - 19s 6ms/step - loss: 0.0055 - accuracy: 0.9980 - val_loss: 0.0098 - val_accuracy: 0.9977\n",
      "Epoch 20/50\n",
      "3261/3261 [==============================] - 19s 6ms/step - loss: 0.0057 - accuracy: 0.9981 - val_loss: 0.0098 - val_accuracy: 0.9977\n",
      "Epoch 21/50\n",
      "3261/3261 [==============================] - 19s 6ms/step - loss: 0.0051 - accuracy: 0.9982 - val_loss: 0.0120 - val_accuracy: 0.9974\n",
      "Epoch 22/50\n",
      "3261/3261 [==============================] - 18s 6ms/step - loss: 0.0051 - accuracy: 0.9982 - val_loss: 0.0092 - val_accuracy: 0.9981\n",
      "Epoch 23/50\n",
      "3261/3261 [==============================] - 19s 6ms/step - loss: 0.0051 - accuracy: 0.9982 - val_loss: 0.0091 - val_accuracy: 0.9977\n",
      "Epoch 24/50\n",
      "3261/3261 [==============================] - 17s 5ms/step - loss: 0.0050 - accuracy: 0.9984 - val_loss: 0.0084 - val_accuracy: 0.9980\n",
      "Epoch 25/50\n",
      "3261/3261 [==============================] - 19s 6ms/step - loss: 0.0050 - accuracy: 0.9983 - val_loss: 0.0086 - val_accuracy: 0.9982\n",
      "Epoch 26/50\n",
      "3261/3261 [==============================] - 20s 6ms/step - loss: 0.0048 - accuracy: 0.9985 - val_loss: 0.0100 - val_accuracy: 0.9982\n",
      "Epoch 27/50\n",
      "3261/3261 [==============================] - 19s 6ms/step - loss: 0.0046 - accuracy: 0.9984 - val_loss: 0.0113 - val_accuracy: 0.9975\n",
      "Epoch 28/50\n",
      "3261/3261 [==============================] - 19s 6ms/step - loss: 0.0047 - accuracy: 0.9983 - val_loss: 0.0091 - val_accuracy: 0.9984\n",
      "Epoch 29/50\n",
      "3261/3261 [==============================] - 19s 6ms/step - loss: 0.0048 - accuracy: 0.9984 - val_loss: 0.0084 - val_accuracy: 0.9987\n",
      "Epoch 30/50\n",
      "3261/3261 [==============================] - 19s 6ms/step - loss: 0.0046 - accuracy: 0.9984 - val_loss: 0.0090 - val_accuracy: 0.9979\n",
      "Epoch 31/50\n",
      "3261/3261 [==============================] - 20s 6ms/step - loss: 0.0046 - accuracy: 0.9986 - val_loss: 0.0079 - val_accuracy: 0.9987\n",
      "Epoch 32/50\n",
      "3261/3261 [==============================] - 18s 6ms/step - loss: 0.0043 - accuracy: 0.9986 - val_loss: 0.0091 - val_accuracy: 0.9985\n",
      "Epoch 33/50\n",
      "3261/3261 [==============================] - 19s 6ms/step - loss: 0.0046 - accuracy: 0.9984 - val_loss: 0.0091 - val_accuracy: 0.9984\n",
      "Epoch 34/50\n",
      "3261/3261 [==============================] - 20s 6ms/step - loss: 0.0043 - accuracy: 0.9987 - val_loss: 0.0085 - val_accuracy: 0.9986\n",
      "Epoch 35/50\n",
      "3261/3261 [==============================] - 19s 6ms/step - loss: 0.0042 - accuracy: 0.9987 - val_loss: 0.0080 - val_accuracy: 0.9987\n",
      "Epoch 36/50\n",
      "3261/3261 [==============================] - 20s 6ms/step - loss: 0.0040 - accuracy: 0.9987 - val_loss: 0.0085 - val_accuracy: 0.9985\n",
      "Epoch 37/50\n",
      "3261/3261 [==============================] - 18s 5ms/step - loss: 0.0043 - accuracy: 0.9986 - val_loss: 0.0142 - val_accuracy: 0.9961\n",
      "Epoch 38/50\n",
      "3261/3261 [==============================] - 19s 6ms/step - loss: 0.0042 - accuracy: 0.9988 - val_loss: 0.0118 - val_accuracy: 0.9970\n",
      "Epoch 39/50\n",
      "3261/3261 [==============================] - 18s 6ms/step - loss: 0.0042 - accuracy: 0.9985 - val_loss: 0.0079 - val_accuracy: 0.9985\n",
      "Epoch 40/50\n",
      "3261/3261 [==============================] - 19s 6ms/step - loss: 0.0042 - accuracy: 0.9986 - val_loss: 0.0083 - val_accuracy: 0.9984\n",
      "Epoch 41/50\n",
      "3261/3261 [==============================] - 19s 6ms/step - loss: 0.0039 - accuracy: 0.9988 - val_loss: 0.0079 - val_accuracy: 0.9985\n",
      "Epoch 42/50\n",
      "3261/3261 [==============================] - 18s 6ms/step - loss: 0.0040 - accuracy: 0.9987 - val_loss: 0.0081 - val_accuracy: 0.9985\n",
      "Epoch 43/50\n",
      "3261/3261 [==============================] - 20s 6ms/step - loss: 0.0039 - accuracy: 0.9988 - val_loss: 0.0125 - val_accuracy: 0.9973\n",
      "Epoch 44/50\n",
      "3261/3261 [==============================] - 19s 6ms/step - loss: 0.0038 - accuracy: 0.9986 - val_loss: 0.0082 - val_accuracy: 0.9985\n",
      "Epoch 45/50\n",
      "3261/3261 [==============================] - 19s 6ms/step - loss: 0.0039 - accuracy: 0.9987 - val_loss: 0.0081 - val_accuracy: 0.9982\n",
      "Epoch 46/50\n",
      "3261/3261 [==============================] - 23s 7ms/step - loss: 0.0037 - accuracy: 0.9989 - val_loss: 0.0095 - val_accuracy: 0.9987\n",
      "Epoch 47/50\n",
      "3261/3261 [==============================] - 28s 9ms/step - loss: 0.0039 - accuracy: 0.9987 - val_loss: 0.0084 - val_accuracy: 0.9986\n",
      "Epoch 48/50\n",
      "3261/3261 [==============================] - 27s 8ms/step - loss: 0.0039 - accuracy: 0.9987 - val_loss: 0.0075 - val_accuracy: 0.9986\n",
      "Epoch 49/50\n",
      "3261/3261 [==============================] - 26s 8ms/step - loss: 0.0037 - accuracy: 0.9988 - val_loss: 0.0089 - val_accuracy: 0.9986\n",
      "Epoch 50/50\n",
      "3261/3261 [==============================] - 29s 9ms/step - loss: 0.0037 - accuracy: 0.9988 - val_loss: 0.0078 - val_accuracy: 0.9985\n"
     ]
    }
   ],
   "source": [
    "history = model1.fit(XDoS_train, YDoS_train, batch_size=32, epochs=50, validation_data=(XDoS_test, YDoS_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "242ee857",
   "metadata": {},
   "source": [
    "#    - Probe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "5932f38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Probe_df.drop(labels= ['label'], axis=1, inplace=True)\n",
    "YProbe_train = Probe_df['intrusion']\n",
    "XProbe_train = Probe_df.drop(labels= ['intrusion'], axis=1)\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "YProbe_train = LabelBinarizer().fit_transform(YProbe_train)\n",
    "\n",
    "XProbe_train=np.array(XProbe_train)\n",
    "YProbe_train=np.array(YProbe_train)\n",
    "XProbe_train, XProbe_test, YProbe_train, YProbe_test = train_test_split(XProbe_train, YProbe_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# reshape input to be [samples, time steps, features]\n",
    "XProbe_train = np.reshape(XProbe_train, ( XProbe_train.shape[0], XProbe_train.shape[1],1 ))\n",
    "XProbe_test = np.reshape(XProbe_test, ( XProbe_test.shape[0],  XProbe_test.shape[1],1 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "836403d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_7 (Conv1D)           (None, 120, 32)           128       \n",
      "                                                                 \n",
      " max_pooling1d_6 (MaxPooling  (None, 40, 32)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " flatten_6 (Flatten)         (None, 1280)              0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 128)               163968    \n",
      "                                                                 \n",
      " dropout_14 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 164,225\n",
      "Trainable params: 164,225\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# create CNN model\n",
    "model2 = Sequential()\n",
    "\n",
    "# add convolutional layer with 32 filters, kernel size of 3x3 and activation function ReLU\n",
    "model2.add(Conv1D(32, kernel_size=3,activation='relu', input_shape=( XProbe_train.shape[1],XProbe_train.shape[2])))\n",
    "\n",
    "# add max pooling layer\n",
    "model2.add(MaxPool1D(pool_size=3))\n",
    "\n",
    "# add flatten layer to convert output of convolutional layer to 1D array\n",
    "model2.add(Flatten())\n",
    "\n",
    "\n",
    "# add dense layer with 128 neurons and activation function ReLU\n",
    "model2.add(Dense(128, activation='relu'))\n",
    "\n",
    "# add dropout layer with rate of 0.2 to prevent overfitting\n",
    "model2.add(Dropout(0.2))\n",
    "\n",
    "# add output layer with 1 neuron and sigmoid activation function for binary classification\n",
    "model2.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# compile model with binary crossentropy loss function and Adam optimizer\n",
    "model2.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# print model summary\n",
    "model2.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "fe19df72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "2279/2279 [==============================] - 16s 6ms/step - loss: 0.0483 - accuracy: 0.9837 - val_loss: 0.0305 - val_accuracy: 0.9900\n",
      "Epoch 2/50\n",
      "2279/2279 [==============================] - 15s 6ms/step - loss: 0.0301 - accuracy: 0.9908 - val_loss: 0.0234 - val_accuracy: 0.9919\n",
      "Epoch 3/50\n",
      "2279/2279 [==============================] - 19s 8ms/step - loss: 0.0250 - accuracy: 0.9923 - val_loss: 0.0199 - val_accuracy: 0.9945\n",
      "Epoch 4/50\n",
      "2279/2279 [==============================] - 21s 9ms/step - loss: 0.0219 - accuracy: 0.9932 - val_loss: 0.0174 - val_accuracy: 0.9954\n",
      "Epoch 5/50\n",
      "2279/2279 [==============================] - 37s 16ms/step - loss: 0.0197 - accuracy: 0.9939 - val_loss: 0.0180 - val_accuracy: 0.9949\n",
      "Epoch 6/50\n",
      "2279/2279 [==============================] - 17s 8ms/step - loss: 0.0186 - accuracy: 0.9942 - val_loss: 0.0150 - val_accuracy: 0.9951\n",
      "Epoch 7/50\n",
      "2279/2279 [==============================] - 16s 7ms/step - loss: 0.0168 - accuracy: 0.9945 - val_loss: 0.0245 - val_accuracy: 0.9928\n",
      "Epoch 8/50\n",
      "2279/2279 [==============================] - 16s 7ms/step - loss: 0.0161 - accuracy: 0.9947 - val_loss: 0.0137 - val_accuracy: 0.9963\n",
      "Epoch 9/50\n",
      "2279/2279 [==============================] - 140s 62ms/step - loss: 0.0160 - accuracy: 0.9952 - val_loss: 0.0123 - val_accuracy: 0.9966\n",
      "Epoch 10/50\n",
      "2279/2279 [==============================] - 20s 9ms/step - loss: 0.0147 - accuracy: 0.9952 - val_loss: 0.0145 - val_accuracy: 0.9955\n",
      "Epoch 11/50\n",
      "2279/2279 [==============================] - 14s 6ms/step - loss: 0.0142 - accuracy: 0.9956 - val_loss: 0.0133 - val_accuracy: 0.9959\n",
      "Epoch 12/50\n",
      "2279/2279 [==============================] - 18s 8ms/step - loss: 0.0137 - accuracy: 0.9957 - val_loss: 0.0121 - val_accuracy: 0.9963\n",
      "Epoch 13/50\n",
      "2279/2279 [==============================] - 16s 7ms/step - loss: 0.0131 - accuracy: 0.9957 - val_loss: 0.0120 - val_accuracy: 0.9966\n",
      "Epoch 14/50\n",
      "2279/2279 [==============================] - 15s 6ms/step - loss: 0.0126 - accuracy: 0.9957 - val_loss: 0.0130 - val_accuracy: 0.9962\n",
      "Epoch 15/50\n",
      "2279/2279 [==============================] - 17s 7ms/step - loss: 0.0125 - accuracy: 0.9959 - val_loss: 0.0128 - val_accuracy: 0.9965\n",
      "Epoch 16/50\n",
      "2279/2279 [==============================] - 23s 10ms/step - loss: 0.0116 - accuracy: 0.9960 - val_loss: 0.0129 - val_accuracy: 0.9965\n",
      "Epoch 17/50\n",
      "2279/2279 [==============================] - 24s 10ms/step - loss: 0.0116 - accuracy: 0.9960 - val_loss: 0.0121 - val_accuracy: 0.9970\n",
      "Epoch 18/50\n",
      "2279/2279 [==============================] - 24s 10ms/step - loss: 0.0112 - accuracy: 0.9963 - val_loss: 0.0120 - val_accuracy: 0.9967\n",
      "Epoch 19/50\n",
      "2279/2279 [==============================] - 26s 11ms/step - loss: 0.0110 - accuracy: 0.9963 - val_loss: 0.0109 - val_accuracy: 0.9974\n",
      "Epoch 20/50\n",
      "2279/2279 [==============================] - 24s 11ms/step - loss: 0.0107 - accuracy: 0.9961 - val_loss: 0.0114 - val_accuracy: 0.9966\n",
      "Epoch 21/50\n",
      "2279/2279 [==============================] - 24s 11ms/step - loss: 0.0108 - accuracy: 0.9963 - val_loss: 0.0125 - val_accuracy: 0.9962\n",
      "Epoch 22/50\n",
      "2279/2279 [==============================] - 27s 12ms/step - loss: 0.0105 - accuracy: 0.9964 - val_loss: 0.0124 - val_accuracy: 0.9969\n",
      "Epoch 23/50\n",
      "2279/2279 [==============================] - 28s 12ms/step - loss: 0.0102 - accuracy: 0.9965 - val_loss: 0.0123 - val_accuracy: 0.9963\n",
      "Epoch 24/50\n",
      "2279/2279 [==============================] - 26s 11ms/step - loss: 0.0101 - accuracy: 0.9965 - val_loss: 0.0118 - val_accuracy: 0.9967\n",
      "Epoch 25/50\n",
      "2279/2279 [==============================] - 24s 11ms/step - loss: 0.0098 - accuracy: 0.9966 - val_loss: 0.0108 - val_accuracy: 0.9971\n",
      "Epoch 26/50\n",
      "2279/2279 [==============================] - 23s 10ms/step - loss: 0.0099 - accuracy: 0.9966 - val_loss: 0.0109 - val_accuracy: 0.9973\n",
      "Epoch 27/50\n",
      "2279/2279 [==============================] - 23s 10ms/step - loss: 0.0097 - accuracy: 0.9967 - val_loss: 0.0108 - val_accuracy: 0.9968\n",
      "Epoch 28/50\n",
      "2279/2279 [==============================] - 23s 10ms/step - loss: 0.0092 - accuracy: 0.9969 - val_loss: 0.0115 - val_accuracy: 0.9967\n",
      "Epoch 29/50\n",
      "2279/2279 [==============================] - 22s 10ms/step - loss: 0.0092 - accuracy: 0.9967 - val_loss: 0.0115 - val_accuracy: 0.9973\n",
      "Epoch 30/50\n",
      "2279/2279 [==============================] - 23s 10ms/step - loss: 0.0092 - accuracy: 0.9966 - val_loss: 0.0112 - val_accuracy: 0.9972\n",
      "Epoch 31/50\n",
      "2279/2279 [==============================] - 22s 10ms/step - loss: 0.0094 - accuracy: 0.9967 - val_loss: 0.0113 - val_accuracy: 0.9968\n",
      "Epoch 32/50\n",
      "2279/2279 [==============================] - 22s 9ms/step - loss: 0.0089 - accuracy: 0.9971 - val_loss: 0.0126 - val_accuracy: 0.9964\n",
      "Epoch 33/50\n",
      "2279/2279 [==============================] - 23s 10ms/step - loss: 0.0092 - accuracy: 0.9968 - val_loss: 0.0105 - val_accuracy: 0.9973\n",
      "Epoch 34/50\n",
      "2279/2279 [==============================] - 25s 11ms/step - loss: 0.0090 - accuracy: 0.9968 - val_loss: 0.0110 - val_accuracy: 0.9971\n",
      "Epoch 35/50\n",
      "2279/2279 [==============================] - 21s 9ms/step - loss: 0.0086 - accuracy: 0.9969 - val_loss: 0.0108 - val_accuracy: 0.9968\n",
      "Epoch 36/50\n",
      "2279/2279 [==============================] - 22s 10ms/step - loss: 0.0084 - accuracy: 0.9969 - val_loss: 0.0115 - val_accuracy: 0.9971\n",
      "Epoch 37/50\n",
      "2279/2279 [==============================] - 22s 10ms/step - loss: 0.0088 - accuracy: 0.9969 - val_loss: 0.0113 - val_accuracy: 0.9970\n",
      "Epoch 38/50\n",
      "2279/2279 [==============================] - 21s 9ms/step - loss: 0.0084 - accuracy: 0.9971 - val_loss: 0.0111 - val_accuracy: 0.9973\n",
      "Epoch 39/50\n",
      "2279/2279 [==============================] - 21s 9ms/step - loss: 0.0080 - accuracy: 0.9973 - val_loss: 0.0113 - val_accuracy: 0.9968\n",
      "Epoch 40/50\n",
      "2279/2279 [==============================] - 22s 10ms/step - loss: 0.0085 - accuracy: 0.9970 - val_loss: 0.0107 - val_accuracy: 0.9976\n",
      "Epoch 41/50\n",
      "2279/2279 [==============================] - 23s 10ms/step - loss: 0.0083 - accuracy: 0.9970 - val_loss: 0.0121 - val_accuracy: 0.9967\n",
      "Epoch 42/50\n",
      "2279/2279 [==============================] - 22s 10ms/step - loss: 0.0078 - accuracy: 0.9973 - val_loss: 0.0113 - val_accuracy: 0.9971\n",
      "Epoch 43/50\n",
      "2279/2279 [==============================] - 21s 9ms/step - loss: 0.0084 - accuracy: 0.9970 - val_loss: 0.0099 - val_accuracy: 0.9977\n",
      "Epoch 44/50\n",
      "2279/2279 [==============================] - 25s 11ms/step - loss: 0.0079 - accuracy: 0.9971 - val_loss: 0.0116 - val_accuracy: 0.9968\n",
      "Epoch 45/50\n",
      "2279/2279 [==============================] - 24s 11ms/step - loss: 0.0080 - accuracy: 0.9972 - val_loss: 0.0105 - val_accuracy: 0.9975\n",
      "Epoch 46/50\n",
      "2279/2279 [==============================] - 22s 10ms/step - loss: 0.0081 - accuracy: 0.9971 - val_loss: 0.0102 - val_accuracy: 0.9975\n",
      "Epoch 47/50\n",
      "2279/2279 [==============================] - 22s 10ms/step - loss: 0.0076 - accuracy: 0.9973 - val_loss: 0.0120 - val_accuracy: 0.9968\n",
      "Epoch 48/50\n",
      "2279/2279 [==============================] - 22s 10ms/step - loss: 0.0077 - accuracy: 0.9971 - val_loss: 0.0109 - val_accuracy: 0.9974\n",
      "Epoch 49/50\n",
      "2279/2279 [==============================] - 21s 9ms/step - loss: 0.0078 - accuracy: 0.9973 - val_loss: 0.0133 - val_accuracy: 0.9972\n",
      "Epoch 50/50\n",
      "2279/2279 [==============================] - 21s 9ms/step - loss: 0.0078 - accuracy: 0.9971 - val_loss: 0.0098 - val_accuracy: 0.9976\n"
     ]
    }
   ],
   "source": [
    "history = model2.fit(XProbe_train, YProbe_train, batch_size=32, epochs=50, validation_data=(XProbe_test, YProbe_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc0faf3",
   "metadata": {},
   "source": [
    "# - R2L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "1e6100e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "R2L_df.drop(labels= ['label'], axis=1, inplace=True)\n",
    "YR2L_train = R2L_df['intrusion']\n",
    "XR2L_train = R2L_df.drop(labels= ['intrusion'], axis=1)\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "YR2L_train = LabelBinarizer().fit_transform(YR2L_train)\n",
    "\n",
    "XR2L_train=np.array(XR2L_train)\n",
    "YR2L_train=np.array(YR2L_train)\n",
    "XR2L_train, XR2L_test, YR2L_train, YR2L_test = train_test_split(XR2L_train, YR2L_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# reshape input to be [samples, time steps, features]\n",
    "XR2L_train = np.reshape(XR2L_train, ( XR2L_train.shape[0], XR2L_train.shape[1],1 ))\n",
    "XR2L_test = np.reshape(XR2L_test, ( XR2L_test.shape[0],  XR2L_test.shape[1],1 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "cae1f84b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_8 (Conv1D)           (None, 120, 32)           128       \n",
      "                                                                 \n",
      " max_pooling1d_7 (MaxPooling  (None, 40, 32)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " flatten_7 (Flatten)         (None, 1280)              0         \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 128)               163968    \n",
      "                                                                 \n",
      " dropout_15 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 164,225\n",
      "Trainable params: 164,225\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# create CNN model\n",
    "model3 = Sequential()\n",
    "\n",
    "# add convolutional layer with 32 filters, kernel size of 3x3 and activation function ReLU\n",
    "model3.add(Conv1D(32, kernel_size=3,activation='relu', input_shape=( XR2L_train.shape[1],XR2L_train.shape[2])))\n",
    "\n",
    "# add max pooling layer\n",
    "model3.add(MaxPool1D(pool_size=3))\n",
    "\n",
    "# add flatten layer to convert output of convolutional layer to 1D array\n",
    "model3.add(Flatten())\n",
    "\n",
    "\n",
    "# add dense layer with 128 neurons and activation function ReLU\n",
    "model3.add(Dense(128, activation='relu'))\n",
    "\n",
    "# add dropout layer with rate of 0.2 to prevent overfitting\n",
    "model3.add(Dropout(0.2))\n",
    "\n",
    "# add output layer with 1 neuron and sigmoid activation function for binary classification\n",
    "model3.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# compile model with binary crossentropy loss function and Adam optimizer\n",
    "model3.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# print model summary\n",
    "model3.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "4d9a44d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "2024/2024 [==============================] - 73s 9ms/step - loss: 0.0706 - accuracy: 0.9717 - val_loss: 0.0512 - val_accuracy: 0.9812\n",
      "Epoch 2/50\n",
      "2024/2024 [==============================] - 20s 10ms/step - loss: 0.0515 - accuracy: 0.9790 - val_loss: 0.0475 - val_accuracy: 0.9830\n",
      "Epoch 3/50\n",
      "2024/2024 [==============================] - 20s 10ms/step - loss: 0.0471 - accuracy: 0.9810 - val_loss: 0.0447 - val_accuracy: 0.9810\n",
      "Epoch 4/50\n",
      "2024/2024 [==============================] - 19s 9ms/step - loss: 0.0444 - accuracy: 0.9822 - val_loss: 0.0418 - val_accuracy: 0.9832\n",
      "Epoch 5/50\n",
      "2024/2024 [==============================] - 20s 10ms/step - loss: 0.0427 - accuracy: 0.9823 - val_loss: 0.0395 - val_accuracy: 0.9872\n",
      "Epoch 6/50\n",
      "2024/2024 [==============================] - 19s 10ms/step - loss: 0.0405 - accuracy: 0.9832 - val_loss: 0.0386 - val_accuracy: 0.9862\n",
      "Epoch 7/50\n",
      "2024/2024 [==============================] - 20s 10ms/step - loss: 0.0394 - accuracy: 0.9837 - val_loss: 0.0413 - val_accuracy: 0.9836\n",
      "Epoch 8/50\n",
      "2024/2024 [==============================] - 19s 9ms/step - loss: 0.0386 - accuracy: 0.9842 - val_loss: 0.0376 - val_accuracy: 0.9854\n",
      "Epoch 9/50\n",
      "2024/2024 [==============================] - 20s 10ms/step - loss: 0.0374 - accuracy: 0.9846 - val_loss: 0.0411 - val_accuracy: 0.9858\n",
      "Epoch 10/50\n",
      "2024/2024 [==============================] - 19s 9ms/step - loss: 0.0370 - accuracy: 0.9853 - val_loss: 0.0360 - val_accuracy: 0.9868\n",
      "Epoch 11/50\n",
      "2024/2024 [==============================] - 20s 10ms/step - loss: 0.0360 - accuracy: 0.9851 - val_loss: 0.0345 - val_accuracy: 0.9873\n",
      "Epoch 12/50\n",
      "2024/2024 [==============================] - 22s 11ms/step - loss: 0.0351 - accuracy: 0.9858 - val_loss: 0.0366 - val_accuracy: 0.9854\n",
      "Epoch 13/50\n",
      "2024/2024 [==============================] - 19s 9ms/step - loss: 0.0346 - accuracy: 0.9859 - val_loss: 0.0341 - val_accuracy: 0.9886\n",
      "Epoch 14/50\n",
      "2024/2024 [==============================] - 20s 10ms/step - loss: 0.0352 - accuracy: 0.9851 - val_loss: 0.0354 - val_accuracy: 0.9878\n",
      "Epoch 15/50\n",
      "2024/2024 [==============================] - 20s 10ms/step - loss: 0.0339 - accuracy: 0.9859 - val_loss: 0.0343 - val_accuracy: 0.9883\n",
      "Epoch 16/50\n",
      "2024/2024 [==============================] - 19s 10ms/step - loss: 0.0337 - accuracy: 0.9861 - val_loss: 0.0347 - val_accuracy: 0.9853\n",
      "Epoch 17/50\n",
      "2024/2024 [==============================] - 19s 9ms/step - loss: 0.0333 - accuracy: 0.9863 - val_loss: 0.0326 - val_accuracy: 0.9889\n",
      "Epoch 18/50\n",
      "2024/2024 [==============================] - 18s 9ms/step - loss: 0.0331 - accuracy: 0.9863 - val_loss: 0.0332 - val_accuracy: 0.9875\n",
      "Epoch 19/50\n",
      "2024/2024 [==============================] - 20s 10ms/step - loss: 0.0327 - accuracy: 0.9866 - val_loss: 0.0328 - val_accuracy: 0.9887\n",
      "Epoch 20/50\n",
      "2024/2024 [==============================] - 19s 10ms/step - loss: 0.0324 - accuracy: 0.9862 - val_loss: 0.0315 - val_accuracy: 0.9893\n",
      "Epoch 21/50\n",
      "2024/2024 [==============================] - 18s 9ms/step - loss: 0.0317 - accuracy: 0.9868 - val_loss: 0.0380 - val_accuracy: 0.9867\n",
      "Epoch 22/50\n",
      "2024/2024 [==============================] - 17s 8ms/step - loss: 0.0314 - accuracy: 0.9872 - val_loss: 0.0311 - val_accuracy: 0.9900\n",
      "Epoch 23/50\n",
      "2024/2024 [==============================] - 17s 9ms/step - loss: 0.0312 - accuracy: 0.9868 - val_loss: 0.0311 - val_accuracy: 0.9868\n",
      "Epoch 24/50\n",
      "2024/2024 [==============================] - 19s 9ms/step - loss: 0.0308 - accuracy: 0.9873 - val_loss: 0.0317 - val_accuracy: 0.9894\n",
      "Epoch 25/50\n",
      "2024/2024 [==============================] - 20s 10ms/step - loss: 0.0303 - accuracy: 0.9872 - val_loss: 0.0331 - val_accuracy: 0.9865\n",
      "Epoch 26/50\n",
      "2024/2024 [==============================] - 25s 12ms/step - loss: 0.0301 - accuracy: 0.9875 - val_loss: 0.0317 - val_accuracy: 0.9888\n",
      "Epoch 27/50\n",
      "2024/2024 [==============================] - 24s 12ms/step - loss: 0.0303 - accuracy: 0.9872 - val_loss: 0.0305 - val_accuracy: 0.9892\n",
      "Epoch 28/50\n",
      "2024/2024 [==============================] - 22s 11ms/step - loss: 0.0295 - accuracy: 0.9875 - val_loss: 0.0335 - val_accuracy: 0.9891\n",
      "Epoch 29/50\n",
      "2024/2024 [==============================] - 21s 11ms/step - loss: 0.0294 - accuracy: 0.9875 - val_loss: 0.0352 - val_accuracy: 0.9881\n",
      "Epoch 30/50\n",
      "2024/2024 [==============================] - 22s 11ms/step - loss: 0.0295 - accuracy: 0.9874 - val_loss: 0.0300 - val_accuracy: 0.9899\n",
      "Epoch 31/50\n",
      "2024/2024 [==============================] - 22s 11ms/step - loss: 0.0292 - accuracy: 0.9874 - val_loss: 0.0324 - val_accuracy: 0.9902\n",
      "Epoch 32/50\n",
      "2024/2024 [==============================] - 22s 11ms/step - loss: 0.0292 - accuracy: 0.9879 - val_loss: 0.0315 - val_accuracy: 0.9901\n",
      "Epoch 33/50\n",
      "2024/2024 [==============================] - 23s 11ms/step - loss: 0.0293 - accuracy: 0.9877 - val_loss: 0.0304 - val_accuracy: 0.9897\n",
      "Epoch 34/50\n",
      "2024/2024 [==============================] - 21s 11ms/step - loss: 0.0283 - accuracy: 0.9878 - val_loss: 0.0324 - val_accuracy: 0.9874\n",
      "Epoch 35/50\n",
      "2024/2024 [==============================] - 24s 12ms/step - loss: 0.0282 - accuracy: 0.9880 - val_loss: 0.0381 - val_accuracy: 0.9867\n",
      "Epoch 36/50\n",
      "2024/2024 [==============================] - 23s 11ms/step - loss: 0.0281 - accuracy: 0.9881 - val_loss: 0.0299 - val_accuracy: 0.9905\n",
      "Epoch 37/50\n",
      "2024/2024 [==============================] - 21s 11ms/step - loss: 0.0280 - accuracy: 0.9879 - val_loss: 0.0296 - val_accuracy: 0.9901\n",
      "Epoch 38/50\n",
      "2024/2024 [==============================] - 22s 11ms/step - loss: 0.0283 - accuracy: 0.9880 - val_loss: 0.0304 - val_accuracy: 0.9913\n",
      "Epoch 39/50\n",
      "2024/2024 [==============================] - 22s 11ms/step - loss: 0.0278 - accuracy: 0.9882 - val_loss: 0.0315 - val_accuracy: 0.9902\n",
      "Epoch 40/50\n",
      "2024/2024 [==============================] - 22s 11ms/step - loss: 0.0280 - accuracy: 0.9880 - val_loss: 0.0324 - val_accuracy: 0.9901\n",
      "Epoch 41/50\n",
      "2024/2024 [==============================] - 21s 10ms/step - loss: 0.0280 - accuracy: 0.9885 - val_loss: 0.0316 - val_accuracy: 0.9880\n",
      "Epoch 42/50\n",
      "2024/2024 [==============================] - 22s 11ms/step - loss: 0.0270 - accuracy: 0.9887 - val_loss: 0.0325 - val_accuracy: 0.9899\n",
      "Epoch 43/50\n",
      "2024/2024 [==============================] - 22s 11ms/step - loss: 0.0270 - accuracy: 0.9888 - val_loss: 0.0291 - val_accuracy: 0.9912\n",
      "Epoch 44/50\n",
      "2024/2024 [==============================] - 24s 12ms/step - loss: 0.0270 - accuracy: 0.9888 - val_loss: 0.0301 - val_accuracy: 0.9900\n",
      "Epoch 45/50\n",
      "2024/2024 [==============================] - 23s 11ms/step - loss: 0.0261 - accuracy: 0.9889 - val_loss: 0.0318 - val_accuracy: 0.9896\n",
      "Epoch 46/50\n",
      "2024/2024 [==============================] - 23s 12ms/step - loss: 0.0264 - accuracy: 0.9892 - val_loss: 0.0293 - val_accuracy: 0.9913\n",
      "Epoch 47/50\n",
      "2024/2024 [==============================] - 22s 11ms/step - loss: 0.0260 - accuracy: 0.9888 - val_loss: 0.0311 - val_accuracy: 0.9881\n",
      "Epoch 48/50\n",
      "2024/2024 [==============================] - 22s 11ms/step - loss: 0.0262 - accuracy: 0.9891 - val_loss: 0.0325 - val_accuracy: 0.9897\n",
      "Epoch 49/50\n",
      "2024/2024 [==============================] - 23s 12ms/step - loss: 0.0256 - accuracy: 0.9894 - val_loss: 0.0303 - val_accuracy: 0.9906\n",
      "Epoch 50/50\n",
      "2024/2024 [==============================] - 22s 11ms/step - loss: 0.0258 - accuracy: 0.9892 - val_loss: 0.0292 - val_accuracy: 0.9912\n"
     ]
    }
   ],
   "source": [
    "history = model3.fit(XR2L_train, YR2L_train, batch_size=32, epochs=50, validation_data=(XR2L_test, YR2L_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a81827",
   "metadata": {},
   "source": [
    "# - U2R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "fe09c4d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_9 (Conv1D)           (None, 120, 32)           128       \n",
      "                                                                 \n",
      " max_pooling1d_8 (MaxPooling  (None, 40, 32)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " flatten_8 (Flatten)         (None, 1280)              0         \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 128)               163968    \n",
      "                                                                 \n",
      " dropout_16 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 164,225\n",
      "Trainable params: 164,225\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "1930/1930 [==============================] - 22s 11ms/step - loss: 0.0099 - accuracy: 0.9983 - val_loss: 0.0040 - val_accuracy: 0.9993\n",
      "Epoch 2/50\n",
      "1930/1930 [==============================] - 21s 11ms/step - loss: 0.0055 - accuracy: 0.9986 - val_loss: 0.0035 - val_accuracy: 0.9992\n",
      "Epoch 3/50\n",
      "1930/1930 [==============================] - 20s 10ms/step - loss: 0.0049 - accuracy: 0.9987 - val_loss: 0.0032 - val_accuracy: 0.9992\n",
      "Epoch 4/50\n",
      "1930/1930 [==============================] - 19s 10ms/step - loss: 0.0044 - accuracy: 0.9988 - val_loss: 0.0038 - val_accuracy: 0.9992\n",
      "Epoch 5/50\n",
      "1930/1930 [==============================] - 19s 10ms/step - loss: 0.0042 - accuracy: 0.9989 - val_loss: 0.0042 - val_accuracy: 0.9993\n",
      "Epoch 6/50\n",
      "1930/1930 [==============================] - 19s 10ms/step - loss: 0.0041 - accuracy: 0.9990 - val_loss: 0.0035 - val_accuracy: 0.9992\n",
      "Epoch 7/50\n",
      "1930/1930 [==============================] - 20s 11ms/step - loss: 0.0038 - accuracy: 0.9989 - val_loss: 0.0039 - val_accuracy: 0.9993\n",
      "Epoch 8/50\n",
      "1930/1930 [==============================] - 21s 11ms/step - loss: 0.0036 - accuracy: 0.9990 - val_loss: 0.0032 - val_accuracy: 0.9993\n",
      "Epoch 9/50\n",
      "1930/1930 [==============================] - 20s 10ms/step - loss: 0.0036 - accuracy: 0.9989 - val_loss: 0.0033 - val_accuracy: 0.9993\n",
      "Epoch 10/50\n",
      "1930/1930 [==============================] - 20s 10ms/step - loss: 0.0034 - accuracy: 0.9990 - val_loss: 0.0035 - val_accuracy: 0.9992\n",
      "Epoch 11/50\n",
      "1930/1930 [==============================] - 20s 11ms/step - loss: 0.0032 - accuracy: 0.9991 - val_loss: 0.0038 - val_accuracy: 0.9992\n",
      "Epoch 12/50\n",
      "1930/1930 [==============================] - 20s 11ms/step - loss: 0.0032 - accuracy: 0.9991 - val_loss: 0.0040 - val_accuracy: 0.9993\n",
      "Epoch 13/50\n",
      "1930/1930 [==============================] - 21s 11ms/step - loss: 0.0032 - accuracy: 0.9990 - val_loss: 0.0037 - val_accuracy: 0.9992\n",
      "Epoch 14/50\n",
      "1930/1930 [==============================] - 20s 10ms/step - loss: 0.0031 - accuracy: 0.9991 - val_loss: 0.0037 - val_accuracy: 0.9991\n",
      "Epoch 15/50\n",
      "1930/1930 [==============================] - 20s 10ms/step - loss: 0.0029 - accuracy: 0.9991 - val_loss: 0.0034 - val_accuracy: 0.9992\n",
      "Epoch 16/50\n",
      "1930/1930 [==============================] - 20s 10ms/step - loss: 0.0031 - accuracy: 0.9991 - val_loss: 0.0037 - val_accuracy: 0.9992\n",
      "Epoch 17/50\n",
      "1930/1930 [==============================] - 20s 10ms/step - loss: 0.0028 - accuracy: 0.9992 - val_loss: 0.0037 - val_accuracy: 0.9991\n",
      "Epoch 18/50\n",
      "1930/1930 [==============================] - 20s 10ms/step - loss: 0.0029 - accuracy: 0.9990 - val_loss: 0.0035 - val_accuracy: 0.9993\n",
      "Epoch 19/50\n",
      "1930/1930 [==============================] - 20s 10ms/step - loss: 0.0027 - accuracy: 0.9991 - val_loss: 0.0042 - val_accuracy: 0.9993\n",
      "Epoch 20/50\n",
      "1930/1930 [==============================] - 20s 10ms/step - loss: 0.0027 - accuracy: 0.9993 - val_loss: 0.0035 - val_accuracy: 0.9991\n",
      "Epoch 21/50\n",
      "1930/1930 [==============================] - 20s 10ms/step - loss: 0.0027 - accuracy: 0.9992 - val_loss: 0.0040 - val_accuracy: 0.9992\n",
      "Epoch 22/50\n",
      "1930/1930 [==============================] - 20s 10ms/step - loss: 0.0027 - accuracy: 0.9992 - val_loss: 0.0044 - val_accuracy: 0.9991\n",
      "Epoch 23/50\n",
      "1930/1930 [==============================] - 20s 11ms/step - loss: 0.0027 - accuracy: 0.9992 - val_loss: 0.0039 - val_accuracy: 0.9990\n",
      "Epoch 24/50\n",
      "1930/1930 [==============================] - 20s 10ms/step - loss: 0.0026 - accuracy: 0.9992 - val_loss: 0.0035 - val_accuracy: 0.9992\n",
      "Epoch 25/50\n",
      "1930/1930 [==============================] - 20s 11ms/step - loss: 0.0026 - accuracy: 0.9993 - val_loss: 0.0038 - val_accuracy: 0.9993\n",
      "Epoch 26/50\n",
      "1930/1930 [==============================] - 20s 10ms/step - loss: 0.0026 - accuracy: 0.9992 - val_loss: 0.0037 - val_accuracy: 0.9993\n",
      "Epoch 27/50\n",
      "1930/1930 [==============================] - 22s 11ms/step - loss: 0.0026 - accuracy: 0.9993 - val_loss: 0.0040 - val_accuracy: 0.9993\n",
      "Epoch 28/50\n",
      "1930/1930 [==============================] - 21s 11ms/step - loss: 0.0027 - accuracy: 0.9992 - val_loss: 0.0037 - val_accuracy: 0.9992\n",
      "Epoch 29/50\n",
      "1930/1930 [==============================] - 20s 10ms/step - loss: 0.0023 - accuracy: 0.9993 - val_loss: 0.0040 - val_accuracy: 0.9992\n",
      "Epoch 30/50\n",
      "1930/1930 [==============================] - 20s 10ms/step - loss: 0.0023 - accuracy: 0.9993 - val_loss: 0.0051 - val_accuracy: 0.9993\n",
      "Epoch 31/50\n",
      "1930/1930 [==============================] - 20s 10ms/step - loss: 0.0026 - accuracy: 0.9992 - val_loss: 0.0041 - val_accuracy: 0.9992\n",
      "Epoch 32/50\n",
      "1930/1930 [==============================] - 20s 11ms/step - loss: 0.0024 - accuracy: 0.9993 - val_loss: 0.0049 - val_accuracy: 0.9992\n",
      "Epoch 33/50\n",
      "1930/1930 [==============================] - 20s 11ms/step - loss: 0.0026 - accuracy: 0.9992 - val_loss: 0.0039 - val_accuracy: 0.9992\n",
      "Epoch 34/50\n",
      "1930/1930 [==============================] - 22s 11ms/step - loss: 0.0025 - accuracy: 0.9993 - val_loss: 0.0036 - val_accuracy: 0.9992\n",
      "Epoch 35/50\n",
      "1930/1930 [==============================] - 20s 11ms/step - loss: 0.0024 - accuracy: 0.9993 - val_loss: 0.0039 - val_accuracy: 0.9992\n",
      "Epoch 36/50\n",
      "1930/1930 [==============================] - 21s 11ms/step - loss: 0.0024 - accuracy: 0.9993 - val_loss: 0.0048 - val_accuracy: 0.9992\n",
      "Epoch 37/50\n",
      "1930/1930 [==============================] - 22s 11ms/step - loss: 0.0024 - accuracy: 0.9993 - val_loss: 0.0055 - val_accuracy: 0.9992\n",
      "Epoch 38/50\n",
      "1930/1930 [==============================] - 21s 11ms/step - loss: 0.0024 - accuracy: 0.9994 - val_loss: 0.0062 - val_accuracy: 0.9993\n",
      "Epoch 39/50\n",
      "1930/1930 [==============================] - 21s 11ms/step - loss: 0.0025 - accuracy: 0.9993 - val_loss: 0.0044 - val_accuracy: 0.9991\n",
      "Epoch 40/50\n",
      "1930/1930 [==============================] - 22s 11ms/step - loss: 0.0025 - accuracy: 0.9993 - val_loss: 0.0039 - val_accuracy: 0.9990\n",
      "Epoch 41/50\n",
      "1930/1930 [==============================] - 25s 13ms/step - loss: 0.0025 - accuracy: 0.9993 - val_loss: 0.0042 - val_accuracy: 0.9992\n",
      "Epoch 42/50\n",
      "1930/1930 [==============================] - 24s 12ms/step - loss: 0.0024 - accuracy: 0.9993 - val_loss: 0.0038 - val_accuracy: 0.9992\n",
      "Epoch 43/50\n",
      "1930/1930 [==============================] - 20s 10ms/step - loss: 0.0023 - accuracy: 0.9993 - val_loss: 0.0040 - val_accuracy: 0.9992\n",
      "Epoch 44/50\n",
      "1930/1930 [==============================] - 20s 10ms/step - loss: 0.0022 - accuracy: 0.9993 - val_loss: 0.0041 - val_accuracy: 0.9992\n",
      "Epoch 45/50\n",
      "1930/1930 [==============================] - 20s 10ms/step - loss: 0.0024 - accuracy: 0.9994 - val_loss: 0.0052 - val_accuracy: 0.9992\n",
      "Epoch 46/50\n",
      "1930/1930 [==============================] - 20s 10ms/step - loss: 0.0024 - accuracy: 0.9993 - val_loss: 0.0043 - val_accuracy: 0.9992\n",
      "Epoch 47/50\n",
      "1930/1930 [==============================] - 20s 10ms/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.0052 - val_accuracy: 0.9992\n",
      "Epoch 48/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1930/1930 [==============================] - 21s 11ms/step - loss: 0.0023 - accuracy: 0.9993 - val_loss: 0.0048 - val_accuracy: 0.9992\n",
      "Epoch 49/50\n",
      "1930/1930 [==============================] - 21s 11ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.0044 - val_accuracy: 0.9992\n",
      "Epoch 50/50\n",
      "1930/1930 [==============================] - 20s 10ms/step - loss: 0.0023 - accuracy: 0.9993 - val_loss: 0.0040 - val_accuracy: 0.9991\n"
     ]
    }
   ],
   "source": [
    "U2R_df.drop(labels= ['label'], axis=1, inplace=True)\n",
    "YU2R_train = U2R_df['intrusion']\n",
    "XU2R_train = U2R_df.drop(labels= ['intrusion'], axis=1)\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "YU2R_train = LabelBinarizer().fit_transform(YU2R_train)\n",
    "\n",
    "XU2R_train=np.array(XU2R_train)\n",
    "YU2R_train=np.array(YU2R_train)\n",
    "XU2R_train, XU2R_test, YU2R_train, YU2R_test = train_test_split(XU2R_train, YU2R_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# reshape input to be [samples, time steps, features]\n",
    "XU2R_train = np.reshape(XU2R_train, ( XU2R_train.shape[0], XU2R_train.shape[1],1 ))\n",
    "XU2R_test = np.reshape(XU2R_test, ( XU2R_test.shape[0],  XU2R_test.shape[1],1 ))\n",
    "\n",
    "# create CNN model\n",
    "model4 = Sequential()\n",
    "\n",
    "# add convolutional layer with 32 filters, kernel size of 3x3 and activation function ReLU\n",
    "model4.add(Conv1D(32, kernel_size=3,activation='relu', input_shape=( XU2R_train.shape[1],XU2R_train.shape[2])))\n",
    "\n",
    "# add max pooling layer\n",
    "model4.add(MaxPool1D(pool_size=3))\n",
    "\n",
    "# add flatten layer to convert output of convolutional layer to 1D array\n",
    "model4.add(Flatten())\n",
    "\n",
    "\n",
    "# add dense layer with 128 neurons and activation function ReLU\n",
    "model4.add(Dense(128, activation='relu'))\n",
    "\n",
    "# add dropout layer with rate of 0.2 to prevent overfitting\n",
    "model4.add(Dropout(0.2))\n",
    "\n",
    "# add output layer with 1 neuron and sigmoid activation function for binary classification\n",
    "model4.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# compile model with binary crossentropy loss function and Adam optimizer\n",
    "model4.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# print model summary\n",
    "model4.summary()\n",
    "\n",
    "history = model4.fit(XU2R_train, YU2R_train, batch_size=32, epochs=50, validation_data=(XU2R_test, YU2R_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aaab226",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
